{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7658655,"sourceType":"datasetVersion","datasetId":4465444},{"sourceId":7665714,"sourceType":"datasetVersion","datasetId":4470530},{"sourceId":7704395,"sourceType":"datasetVersion","datasetId":4497799}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import (\n    Layer, Input, Dense, Dropout, LayerNormalization,\n    MultiHeadAttention, Add, GlobalAveragePooling2D,\n    Lambda\n)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import f1_score, roc_auc_score, roc_curve, precision_score\nfrom tensorflow.keras.metrics import Precision, Recall, AUC\n\nimport matplotlib.pyplot as plt\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\n\n# Load Data\ndef load_data_with_generator(dataset_path, image_size, batch_size, limit_per_class):\n    datagen = ImageDataGenerator(\n        preprocessing_function=tf.keras.applications.resnet.preprocess_input, \n        horizontal_flip=True,\n        vertical_flip=True,\n        rotation_range=120,\n        width_shift_range=0.3,\n        height_shift_range=0.3,\n        zoom_range=0.3,\n        shear_range=0.3,\n        brightness_range=[0.1, 1.5],\n        validation_split=0.2  # Use this for splitting training and validation\n    )\n\n    train_generator = datagen.flow_from_directory(\n        dataset_path,\n        target_size=(image_size, image_size),\n        batch_size=batch_size,\n        class_mode='categorical',\n        subset='training'\n    )\n\n    validation_generator = datagen.flow_from_directory(\n        dataset_path,\n        target_size=(image_size, image_size),\n        batch_size=batch_size,\n        class_mode='categorical',\n        subset='validation'\n    )\n\n    return train_generator, validation_generator\n\n# Class Token\nclass ClassToken(Layer):\n    def __init__(self, **kwargs):\n        super(ClassToken, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        w_init = tf.random_normal_initializer()\n        self.class_token = tf.Variable(\n            initial_value=w_init(shape=(1, 1, input_shape[-1]), dtype=\"float16\"),\n            trainable=True,\n            name=\"class_token\"\n        )\n\n    def call(self, inputs):\n        batch_size = tf.shape(inputs)[0]\n        broadcasted_class_token = tf.tile(self.class_token, [batch_size, 1, 1])\n        return tf.keras.layers.concatenate([broadcasted_class_token, inputs], axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[1] + 1, input_shape[2])\n\n# Transformer Encoder\ndef transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.2):\n    x = LayerNormalization(epsilon=1e-6)(inputs)\n    attention_out = MultiHeadAttention(num_heads=num_heads, key_dim=head_size, dropout=dropout)(x, x)\n    x = Add()([attention_out, inputs])\n    x = LayerNormalization(epsilon=1e-6)(x)\n    ff_out = Dense(ff_dim, activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\n    ff_out = Dropout(dropout)(ff_out)\n    ff_out = Dense(inputs.shape[-1], kernel_regularizer=l2(1e-4))(ff_out)\n    ff_out = Dropout(dropout)(ff_out)\n    x = Add()([ff_out, x])\n    return x\n\n# ResNet50 Transformer Model\ndef ResNet50Transformer(input_shape, num_classes, transformer_layers, head_size, num_heads, ff_dim, dropout, fine_tune_at=50):\n    inputs = Input(shape=input_shape)\n\n    resnet_model = ResNet50(include_top=False, weights='imagenet', input_tensor=inputs)\n\n    if fine_tune_at is not None:\n        for layer in resnet_model.layers[:fine_tune_at]:\n            if not isinstance(layer, tf.keras.layers.BatchNormalization):\n                layer.trainable = False\n\n    x = resnet_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = tf.expand_dims(x, axis=1)\n    x = ClassToken()(x)\n    for _ in range(transformer_layers):\n        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n\n    x = Dense(4096, activation=\"gelu\")(x)\n    x = Dropout(0.2)(x)\n\n    x = Lambda(lambda x: x[:, 0])(x)\n    x = Dense(num_classes, activation=\"softmax\")(x)\n\n    model = Model(inputs=inputs, outputs=x)\n    return model\n\ndef train_model(model, train_generator, config, num_epochs=120):\n    print(f\"Total number of training samples: {len(train_generator)}\")\n\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n        for batch_start in range(0, len(train_generator), config[\"batch_size\"] * config[\"acc_steps\"]):\n            batch_end = min(batch_start + config[\"batch_size\"] * config[\"acc_steps\"], len(train_generator))\n            print(f\"Batch indices: {batch_start} to {batch_end}\")\n\n            batch_images, batch_labels = train_generator.next()\n\n            with tf.GradientTape() as tape:\n                predictions = model(batch_images)\n                loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(batch_labels, predictions))\n\n            gradients = tape.gradient(loss, model.trainable_variables)\n            model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n            print(f\"Batch Loss: {loss}\")\n\n        model.reset_metrics()\n        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.numpy()}\")\n\ndef evaluate_model(model, test_images, test_labels, config):\n    test_loss = 0.0\n    test_accuracy = 0.0\n    num_batches = len(test_images) // config[\"batch_size\"]\n\n    for i in range(num_batches):\n        start_idx = i * config[\"batch_size\"]\n        end_idx = (i + 1) * config[\"batch_size\"]\n\n        batch_images = np.array(test_images[start_idx:end_idx])\n        batch_labels = np.array(test_labels[start_idx:end_idx])\n\n        batch_loss, batch_accuracy, _, _ = model.evaluate(batch_images, batch_labels, batch_size=config[\"batch_size\"])\n        test_loss += batch_loss\n        test_accuracy += batch_accuracy\n\n    average_test_loss = test_loss / num_batches\n    average_test_accuracy = test_accuracy / num_batches\n\n    print(f\"Average Test Loss: {average_test_loss}, Average Test Accuracy: {average_test_accuracy}\")\n\n\n\n\nif __name__ == \"__main__\":\n    config = {\n        \"num_layers\": 6,\n        \"hidden_dim\": 3072,\n        \"mlp_dim\": 4096,\n        \"num_heads\": 32,\n       # \"patch_size\":64,\n        \"dropout_rate\": 0.2,\n        \"image_size\": 150,\n        \"num_channels\": 3,\n        \"num_classes\": 8,\n        \"batch_size\":32,\n        \"acc_steps\": 4,\n        \"epochs\": 120\n    }\n   # config[\"num_patches\"] = (config[\"image_size\"] // config[\"patch_size\"]) ** 2\n    limit_per_class = None\n    train_generator, val_generator = load_data_with_generator(\n        '//kaggle/input/kather5000images/Kather_texture_2016_image_tiles_3500', config[\"image_size\"], config[\"batch_size\"], limit_per_class\n    )\n\n    model = ResNet50Transformer(\n        input_shape=(150, 150, 3),\n        num_classes=config[\"num_classes\"],\n        transformer_layers=config[\"num_layers\"],\n        head_size=128,\n        num_heads=config[\"num_heads\"],\n        ff_dim=4096,\n        dropout=config[\"dropout_rate\"]\n    )\n\n    initial_learning_rate = 0.0001\n\n    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n        initial_learning_rate, decay_steps=10000, alpha=0.00001\n    )\n    adam_optimizer = Adam(learning_rate=lr_schedule)\n\n    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(\n        adam_optimizer,\n        dynamic=True\n    )\n\n    \n        \n    model.compile(\n    optimizer=optimizer, \n    loss='categorical_crossentropy', \n    metrics=['accuracy', Precision(), Recall()]\n    )\n    checkpoint = ModelCheckpoint('best_model_kather_adamV1.h5', save_best_only=True)\n\n    csv_logger = CSVLogger('training_katherv1.log')\n\n    history = model.fit(\n        train_generator,\n        steps_per_epoch=len(train_generator),\n        epochs=config[\"epochs\"],\n        validation_data=val_generator,\n        callbacks=[checkpoint, csv_logger],\n        verbose=1\n    )\n\n    model.save('trained_model_kather_adamV1.h5')\n\n\nplt.figure(figsize=(18, 6))\n\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='train_loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='train_accuracy')\nplt.plot(history.history['val_accuracy'], label='val_accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-17T20:51:05.218057Z","iopub.execute_input":"2024-02-17T20:51:05.218478Z","iopub.status.idle":"2024-02-17T22:06:09.606416Z","shell.execute_reply.started":"2024-02-17T20:51:05.218447Z","shell.execute_reply":"2024-02-17T22:06:09.605074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom tifffile import imread\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n\nclass ClassToken(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(ClassToken, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        w_init = tf.random_normal_initializer()\n        self.class_token = tf.Variable(\n            initial_value=w_init(shape=(1, 1, input_shape[-1]), dtype=\"float16\"),\n            trainable=True,\n            name=\"class_token\"\n        )\n\n    def call(self, inputs):\n        batch_size = tf.shape(inputs)[0]\n        broadcasted_class_token = tf.tile(self.class_token, [batch_size, 1, 1])\n        return tf.keras.layers.concatenate([broadcasted_class_token, inputs], axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[1] + 1, input_shape[2])\n\nmodel = load_model('/kaggle/input/trainedkathrer/best_model_kather_adamV1.h5', custom_objects={'ClassToken': ClassToken})\n\nclass_names = ['01_TUMOR', '02_STROMA', '03_COMPLEX', '04_LYMPHO', '05_DEBRIS', '06_MUCOSA', '07_ADIPOSE', '08_EMPTY']\n\ntest_images_folder = '/kaggle/input/kather5000images/Kather_texture_2016_image_tiles_1500'\n\ntotal_predictions = 0\ncorrect_predictions = 0\nall_true_labels = []\nall_predicted_labels = []\n\n# Initialize TP, FP, TN, FN counters\nTP = 0\nFP = 0\nTN = 0\nFN = 0\n\nprint(\"Wrong identified images\")\nfor class_folder in class_names:\n    class_folder_path = os.path.join(test_images_folder, class_folder)\n\n    for filename in os.listdir(class_folder_path):\n        if filename.endswith(\".tif\"):\n            image_path = os.path.join(class_folder_path, filename)\n            img = imread(image_path)\n            img_array = img_to_array(img)\n            img_array = np.expand_dims(img_array, axis=0)\n            img_array = preprocess_input(img_array)\n\n            predictions = model.predict(img_array, verbose=0)\n\n            predicted_class_index = np.argmax(predictions)\n            predicted_class_name = class_names[predicted_class_index]\n\n            all_true_labels.append(class_folder)\n            all_predicted_labels.append(predicted_class_name)\n\n            # Check if actual class matches predicted class\n            if predicted_class_name != class_folder:\n                # Print only when the actual class doesn't match the predicted class\n                print(f\"Image: {filename}, Actual Class: {class_folder}, Predicted Class: {predicted_class_name}\")\n\n            # Calculate TP, FP, TN, FN\n            if predicted_class_name == class_folder:\n                correct_predictions += 1\n                TP += 1\n            else:\n                FP += 1\n                FN += 1\n\n            total_predictions += 1\n\naccuracy = correct_predictions / total_predictions\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Print TP, FP, TN, FN\nprint(\"True Positive (TP):\", TP)\nprint(\"False Positive (FP):\", FP)\nprint(\"True Negative (TN):\", TN)\nprint(\"False Negative (FN):\", FN)\n\nconf_matrix = confusion_matrix(all_true_labels, all_predicted_labels, labels=class_names)\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\n\nplt.xticks(np.arange(len(class_names)), class_names, rotation=45)\nplt.yticks(np.arange(len(class_names)), class_names)\n\nplt.show()\n\nclassification_rep = classification_report(all_true_labels, all_predicted_labels, target_names=class_names)\nprint(\"Classification Report:\\n\", classification_rep)","metadata":{"execution":{"iopub.status.busy":"2024-02-24T18:38:53.122492Z","iopub.execute_input":"2024-02-24T18:38:53.123327Z","iopub.status.idle":"2024-02-24T18:41:14.063885Z","shell.execute_reply.started":"2024-02-24T18:38:53.123292Z","shell.execute_reply":"2024-02-24T18:41:14.062912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom tifffile import imread\nfrom sklearn.metrics import (\n    confusion_matrix, classification_report,\n    precision_score, recall_score, f1_score, hamming_loss,\n    cohen_kappa_score, matthews_corrcoef\n)\nfrom scipy.stats import pearsonr\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n\nclass ClassToken(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(ClassToken, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        w_init = tf.random_normal_initializer()\n        self.class_token = tf.Variable(\n            initial_value=w_init(shape=(1, 1, input_shape[-1]), dtype=\"float16\"),\n            trainable=True,\n            name=\"class_token\"\n        )\n\n    def call(self, inputs):\n        batch_size = tf.shape(inputs)[0]\n        broadcasted_class_token = tf.tile(self.class_token, [batch_size, 1, 1])\n        return tf.keras.layers.concatenate([broadcasted_class_token, inputs], axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[1] + 1, input_shape[2])\n\nmodel = load_model('/kaggle/input/trainedkathrer/best_model_kather_adamV1.h5', custom_objects={'ClassToken': ClassToken})\n\nclass_names = ['01_TUMOR', '02_STROMA', '03_COMPLEX', '04_LYMPHO', '05_DEBRIS', '06_MUCOSA', '07_ADIPOSE', '08_EMPTY']\n\ntest_images_folder = '/kaggle/input/kather5000images/Kather_texture_2016_image_tiles_1500'\n\nall_true_labels = []\nall_predicted_labels = []\nall_predicted_probs = []  # New list to store probabilities\n\nprint(\"Processing images...\")\nfor class_folder in class_names:\n    class_folder_path = os.path.join(test_images_folder, class_folder)\n\n    for filename in os.listdir(class_folder_path):\n        if filename.endswith(\".tif\"):\n            image_path = os.path.join(class_folder_path, filename)\n            img = imread(image_path)\n            img_array = img_to_array(img)\n            img_array = np.expand_dims(img_array, axis=0)\n            img_array = preprocess_input(img_array)\n\n            predictions = model.predict(img_array, verbose=0)\n            predicted_class_index = np.argmax(predictions)\n            predicted_class_name = class_names[predicted_class_index]\n\n            all_true_labels.append(class_folder)\n            all_predicted_labels.append(predicted_class_index)\n            all_predicted_probs.append(predictions[0])  # Store probabilities\n\n\n# Convert class names to numbers for metrics calculation\ntrue_labels_numeric = [class_names.index(label) for label in all_true_labels]\n\n\n# Calculating various metrics\nprecision = precision_score(true_labels_numeric, all_predicted_labels, average='weighted')\nrecall = recall_score(true_labels_numeric, all_predicted_labels, average='weighted')  # Sensitivity\nf1 = f1_score(true_labels_numeric, all_predicted_labels, average='weighted')\nham_loss = hamming_loss(true_labels_numeric, all_predicted_labels)\nkappa = cohen_kappa_score(true_labels_numeric, all_predicted_labels)\nmcc = matthews_corrcoef(true_labels_numeric, all_predicted_labels)\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(true_labels_numeric, all_predicted_labels)\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.xticks(rotation=45)\nplt.yticks(rotation=45)\nplt.show()\n\n# Classification Report\nclassification_rep = classification_report(true_labels_numeric, all_predicted_labels, target_names=class_names)\nprint(\"Classification Report:\\n\", classification_rep)\n\n# Printing the metrics\nprint(f\"Precision: {precision:.2f}\")\nprint(f\"Recall/Sensitivity: {recall:.2f}\")\nprint(f\"F1 Score: {f1:.2f}\")\nprint(f\"Hamming Loss: {ham_loss:.2f}\")\nprint(f\"Cohen's Kappa Score: {kappa:.2f}\")\nprint(f\"Matthews Correlation Coefficient: {mcc:.2f}\")\n\n# Calculate the Pearson correlation coefficient\npredicted_probs_true_class = [probs[class_index] for probs, class_index in zip(all_predicted_probs, true_labels_numeric)]\ncorrelation, _ = pearsonr(predicted_probs_true_class, true_labels_numeric)\nprint(f\"Pearson Correlation Coefficient: {correlation:.2f}\")\n\n# Calculating and printing class-wise accuracy\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\nprint(\"Class-wise Accuracy:\")\nfor class_name, accuracy in zip(class_names, class_accuracies):\n    print(f\"{class_name}: {accuracy:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-24T19:21:35.489155Z","iopub.execute_input":"2024-02-24T19:21:35.489544Z","iopub.status.idle":"2024-02-24T19:23:50.319501Z","shell.execute_reply.started":"2024-02-24T19:21:35.489517Z","shell.execute_reply":"2024-02-24T19:23:50.318561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom tifffile import imread\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n\nclass ClassToken(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(ClassToken, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        w_init = tf.random_normal_initializer()\n        self.class_token = tf.Variable(\n            initial_value=w_init(shape=(1, 1, input_shape[-1]), dtype=\"float16\"),\n            trainable=True,\n            name=\"class_token\"\n        )\n\n    def call(self, inputs):\n        batch_size = tf.shape(inputs)[0]\n        broadcasted_class_token = tf.tile(self.class_token, [batch_size, 1, 1])\n        return tf.keras.layers.concatenate([broadcasted_class_token, inputs], axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[1] + 1, input_shape[2])\n\n# Load the model\nmodel = load_model('/kaggle/input/trainedkathrer/best_model_kather_adamV1.h5', custom_objects={'ClassToken': ClassToken})\n\nclass_names = ['01_TUMOR', '02_STROMA', '03_COMPLEX', '04_LYMPHO', '05_DEBRIS', '06_MUCOSA', '07_ADIPOSE', '08_EMPTY']\ntest_images_folder = '/kaggle/input/kather5000images/Kather_texture_2016_image_tiles_1500'\n\n# Modify the model to create a feature extractor\nfeature_extractor_layer_index = -3  # Assuming the third last layer is the desired feature extractor layer\nfeature_extractor = tf.keras.models.Model(\n    inputs=model.inputs, \n    outputs=model.layers[feature_extractor_layer_index].output\n)\n\n# Initialize lists for features and labels\nfeatures = []\nlabels = []\n\n# Extract features from the test dataset\nfor class_folder in class_names:\n    class_folder_path = os.path.join(test_images_folder, class_folder)\n    for filename in os.listdir(class_folder_path):\n        if filename.endswith(\".tif\"):\n            image_path = os.path.join(class_folder_path, filename)\n            img = imread(image_path)\n            img_array = img_to_array(img)\n            img_array = np.expand_dims(img_array, axis=0)\n            img_array = preprocess_input(img_array)\n\n            feature = feature_extractor.predict(img_array)\n            features.append(feature[0])\n            labels.append(class_folder)\n\n# Convert to numpy arrays\n# Convert to numpy arrays and flatten the features\nfeatures = np.array(features)\nfeatures = features.reshape(features.shape[0], -1)  # Flatten each feature vector\nlabels = np.array(labels)\n\n# Apply t-SNE for dimensionality reduction\ntsne = TSNE(n_components=2, random_state=0)\nreduced_features = tsne.fit_transform(features)\n\n# Plotting\nplt.figure(figsize=(12, 8))\nfor i, class_name in enumerate(class_names):\n    indices = np.where(labels == class_name)\n    plt.scatter(reduced_features[indices, 0], reduced_features[indices, 1], label=class_name)\n\nplt.title('t-SNE of extracted features')\nplt.xlabel('t-SNE feature 1')\nplt.ylabel('t-SNE feature 2')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T16:20:04.274474Z","iopub.execute_input":"2024-02-26T16:20:04.275315Z","iopub.status.idle":"2024-02-26T16:23:28.236173Z","shell.execute_reply.started":"2024-02-26T16:20:04.275280Z","shell.execute_reply":"2024-02-26T16:23:28.235157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom tifffile import imread\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import Model\nimport matplotlib.cm as cm\nimport matplotlib\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n\n# Custom ClassToken Layer\nclass ClassToken(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(ClassToken, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        w_init = tf.random_normal_initializer()\n        self.class_token = tf.Variable(\n            initial_value=w_init(shape=(1, 1, input_shape[-1]), dtype=\"float16\"),\n            trainable=True,\n            name=\"class_token\"\n        )\n\n    def call(self, inputs):\n        batch_size = tf.shape(inputs)[0]\n        broadcasted_class_token = tf.tile(self.class_token, [batch_size, 1, 1])\n        return tf.keras.layers.concatenate([broadcasted_class_token, inputs], axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[1] + 1, input_shape[2])\n\n# Load the trained model\nmodel = load_model('/kaggle/input/trainedkathrer/best_model_kather_adamV1.h5', custom_objects={'ClassToken': ClassToken})\nclass_names = ['01_TUMOR', '02_STROMA', '03_COMPLEX', '04_LYMPHO', '05_DEBRIS', '06_MUCOSA', '07_ADIPOSE', '08_EMPTY']\ntest_images_folder = '/kaggle/input/kather5000images/Kather_texture_2016_image_tiles_1500'\n\n# Grad-CAM Function\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(predictions[0])\n        loss = predictions[:, pred_index]\n\n    output = conv_outputs[0]\n    grads = tape.gradient(loss, conv_outputs)[0]\n\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n    heatmap = tf.matmul(output, pooled_grads[..., tf.newaxis])\n    heatmap = tf.squeeze(heatmap)\n\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef display_gradcam(img, heatmap, alpha=0.5):\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    \n    # Handle NaN or Inf values in heatmap\n    heatmap = np.nan_to_num(heatmap)\n\n    heatmap = np.uint8(255 * heatmap)\n\n    # Use the recommended method for colormap\n    jet = matplotlib.cm.get_cmap(\"jet\")\n\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n\n    return superimposed_img\n\n# Class names and Test Images Folder\n\n# Visualization for First Five Images from Each Class\ndef get_top_images_with_confidences(class_folder_path, model, num_images=20):\n    image_predictions = []\n    for filename in os.listdir(class_folder_path):\n        if filename.endswith(\".tif\"):\n            image_path = os.path.join(class_folder_path, filename)\n            img = imread(image_path)\n            img_array = img_to_array(img)\n            img_array = np.expand_dims(img_array, axis=0)\n            img_array = preprocess_input(img_array)\n            \n            predictions = model.predict(img_array,verbose=0)\n            image_predictions.append((filename, predictions[0]))  # Store filename and prediction probabilities\n\n    # Sort the images by max confidence and get the top 'num_images'\n    top_images = sorted(image_predictions, key=lambda x: np.max(x[1]), reverse=True)[:num_images]\n    return top_images\n\n# Visualization for Top Images from Each Class\nfor class_folder in class_names:\n    class_folder_path = os.path.join(test_images_folder, class_folder)\n    top_images_with_confidences = get_top_images_with_confidences(class_folder_path, model, num_images=5)\n\n    for filename, confidences in top_images_with_confidences:\n        image_path = os.path.join(class_folder_path, filename)\n        img = imread(image_path)\n        img_array = img_to_array(img)\n        img_array = np.expand_dims(img_array, axis=0)\n        img_array = preprocess_input(img_array)\n\n        # Generate Grad-CAM heatmap\n        heatmap = make_gradcam_heatmap(img_array, model, 'conv5_block3_3_conv')  # Adjust the layer name as needed\n        superimposed_img = display_gradcam(img, heatmap)\n\n        # Displaying the original image, Grad-CAM image, and confidence levels\n        plt.figure(figsize=(12, 4))\n        \n        plt.subplot(1, 3, 1)\n        plt.imshow(img)\n        plt.title(\"Original\")\n        plt.axis('off')\n\n        plt.subplot(1, 3, 2)\n        plt.imshow(superimposed_img)\n        plt.title(f\"Grad-CAM - {class_folder}\")\n        plt.axis('off')\n\n        plt.subplot(1, 3, 3)\n        plt.bar(class_names, confidences)\n        plt.title(\"Class Confidence Levels\")\n        plt.xticks(rotation=45)\n        plt.ylabel(\"Confidence\")\n        plt.tight_layout()\n\n        plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T17:56:28.402361Z","iopub.execute_input":"2024-02-26T17:56:28.403286Z","iopub.status.idle":"2024-02-26T17:59:22.705887Z","shell.execute_reply.started":"2024-02-26T17:56:28.403249Z","shell.execute_reply":"2024-02-26T17:59:22.704947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom tifffile import imread\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import Model\nimport matplotlib.cm as cm\nimport matplotlib\nimport random\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n\n# Custom ClassToken Layer\nclass ClassToken(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(ClassToken, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        w_init = tf.random_normal_initializer()\n        self.class_token = tf.Variable(\n            initial_value=w_init(shape=(1, 1, input_shape[-1]), dtype=\"float16\"),\n            trainable=True,\n            name=\"class_token\"\n        )\n\n    def call(self, inputs):\n        batch_size = tf.shape(inputs)[0]\n        broadcasted_class_token = tf.tile(self.class_token, [batch_size, 1, 1])\n        return tf.keras.layers.concatenate([broadcasted_class_token, inputs], axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[1] + 1, input_shape[2])\n\n# Load the trained model\nmodel = load_model('/kaggle/input/trainedkathrer/best_model_kather_adamV1.h5', custom_objects={'ClassToken': ClassToken})\nclass_names = ['01_TUMOR', '02_STROMA', '03_COMPLEX', '04_LYMPHO', '05_DEBRIS', '06_MUCOSA', '07_ADIPOSE', '08_EMPTY']\ntest_images_folder = '/kaggle/input/kather5000images/Kather_texture_2016_image_tiles_1500'\n\n# Grad-CAM Function\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(predictions[0])\n        loss = predictions[:, pred_index]\n\n    output = conv_outputs[0]\n    grads = tape.gradient(loss, conv_outputs)[0]\n\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n    heatmap = tf.matmul(output, pooled_grads[..., tf.newaxis])\n    heatmap = tf.squeeze(heatmap)\n\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef display_gradcam(img, heatmap, alpha=0.5):\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    \n    # Handle NaN or Inf values in heatmap\n    heatmap = np.nan_to_num(heatmap)\n\n    heatmap = np.uint8(255 * heatmap)\n\n    # Use the recommended method for colormap\n    jet = matplotlib.cm.get_cmap(\"jet\")\n\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n\n    return superimposed_img\n\n# Class names and Test Images Folder\n\n# Visualization for First Five Images from Each Class\ndef get_random_images(class_folder_path, model, num_images=15):\n    all_filenames = [f for f in os.listdir(class_folder_path) if f.endswith(\".tif\")]\n    selected_filenames = random.sample(all_filenames, min(num_images, len(all_filenames)))\n    \n    image_predictions = []\n    for filename in selected_filenames:\n        image_path = os.path.join(class_folder_path, filename)\n        img = imread(image_path)\n        img_array = img_to_array(img)\n        img_array = np.expand_dims(img_array, axis=0)\n        img_array = preprocess_input(img_array)\n        \n        predictions = model.predict(img_array, verbose=0)\n        image_predictions.append((filename, predictions[0]))  # Store filename and prediction probabilities\n\n    return image_predictions\n\nfor class_folder in class_names:\n    class_folder_path = os.path.join(test_images_folder, class_folder)\n    random_images_with_confidences = get_random_images(class_folder_path, model, num_images=15)\n\n    for filename, confidences in random_images_with_confidences:\n        image_path = os.path.join(class_folder_path, filename)\n        img = imread(image_path)\n        img_array = img_to_array(img)\n        img_array = np.expand_dims(img_array, axis=0)\n        img_array = preprocess_input(img_array)\n\n        heatmap = make_gradcam_heatmap(img_array, model, 'conv5_block3_3_conv')\n        superimposed_img = display_gradcam(img, heatmap)\n\n        plt.figure(figsize=(8, 4))\n\n        # Display the Grad-CAM image\n        plt.subplot(1, 2, 1)\n        plt.imshow(superimposed_img)\n        plt.title(f\"Grad-CAM - {class_folder}\")\n        plt.axis('off')\n\n        # Display the confidence percentages\n        plt.subplot(1, 2, 2)\n        confidence_text = \"\\n\".join([f\"{class_name}: {100 * conf:.2f}%\" for class_name, conf in zip(class_names, confidences)])\n        plt.text(0, 0.5, confidence_text, ha='left', va='center', transform=plt.gca().transAxes)\n        plt.axis('off')\n\n        plt.tight_layout()\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-26T18:29:23.969968Z","iopub.execute_input":"2024-02-26T18:29:23.971210Z","iopub.status.idle":"2024-02-26T18:31:05.675278Z","shell.execute_reply.started":"2024-02-26T18:29:23.971178Z","shell.execute_reply":"2024-02-26T18:31:05.674355Z"},"trusted":true},"execution_count":null,"outputs":[]}]}